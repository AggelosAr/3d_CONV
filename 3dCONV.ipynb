{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO5Tg4/rTwkn56p2oWlLQwl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AggelosAr/3d_CONV/blob/main/3dCONV.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xa_Yq1r3K0yq"
      },
      "outputs": [],
      "source": [
        "\n",
        "from math import log10, sqrt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import mixed_precision\n",
        "import time\n",
        "import timeit\n",
        "import os\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))\n",
        "\n",
        "\n",
        "    \n",
        "mixed_precision.set_global_policy('mixed_float16')#mixed_float16\n",
        "tf.config.experimental.tensor_float_32_execution_enabled()\n",
        "os.environ['TF_GPU_THREAD_MODE']='gpu_private'\n",
        "os.environ['TF_GPU_THREAD_COUNT']='1'\n",
        "os.environ['xla_gpu_autotune_level']='4'\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def PSNR(original, compressed):\n",
        "    mse = np.mean((original - compressed) ** 2)\n",
        "    if(mse == 0):  # MSE is zero means no noise is present in the signal .\n",
        "                  # Therefore PSNR have no importance.\n",
        "        return 100\n",
        "    max_pixel = 255.0\n",
        "    psnr = 20 * log10(max_pixel / sqrt(mse))\n",
        "    return psnr\n",
        "\n",
        "\n",
        "class myConv():\n",
        "#class myConv(tf.Module):\n",
        "#class myConv(tf.keras.layers.Layer):\n",
        "    \n",
        "    def __init__(self , no_kernels, input_shape):#input_shape\n",
        "        super(myConv, self).__init__()\n",
        "        \n",
        "        self.A = A                     # ***** NEEDS TO BE PRECOMPUTED *****\n",
        "        self.A_f_T = A_f_T             # ***** NEEDS TO BE PRECOMPUTED *****\n",
        "        self.C_T = C_T                 # ***** NEEDS TO BE PRECOMPUTED *****\n",
        "        \n",
        "        self.kern_num = no_kernels\n",
        "   \n",
        "    #def build(self, input_shape):# TRAINABLE\n",
        "        \n",
        "        self.paddings_image = tf.constant([[0, 0], [0, 2], [0, 0], [0, 2], [0, 2]])\n",
        "        self.bacthes = input_shape[0]\n",
        "        self.frames =  input_shape[1]\n",
        "        self.w = input_shape[2]\n",
        "        self.h = input_shape[3]\n",
        "        self.initial_channels = input_shape[4]\n",
        "        \n",
        "        self.groups_of_2 =  (input_shape[1]//2)*self.initial_channels\n",
        "        self.blocks = (input_shape[2]*input_shape[3])//4\n",
        "\n",
        "        # No of KERNELS and THE INPUT SHAPE ^^ frames x dim1 x dim2 x channels  \n",
        "        default_kernel = tf.keras.initializers.GlorotUniform(seed = 0)(shape=(3, 3, 3, \n",
        "                                                self.initial_channels, self.kern_num),  dtype=precision)\n",
        "        \n",
        "        self.default_kernel = default_kernel\n",
        "       \n",
        "        \n",
        "        self.filters = tf.Variable(default_kernel, trainable=True)#dtype=\"float32\"\n",
        "        #self.bias = self.add_weight(shape=[self.kern_num])\n",
        "       \n",
        "        filters = tf.experimental.numpy.moveaxis(self.filters, 4, 0)\n",
        "        filters = tf.experimental.numpy.moveaxis(filters, 4, 1)\n",
        "        filters = (tf.reverse(filters, axis = [2,3,4]))\n",
        "        paddings = tf.constant([[0, 0], [0, 0], [0, 1], [0, 1], [0, 1]])\n",
        "        self.useable_filters = tf.pad(filters, paddings, \"CONSTANT\")\n",
        "\n",
        "    \n",
        "    def getme(self):\n",
        "        return self.default_kernel\n",
        "   \n",
        "\n",
        "    def trans_conv(self, args): \n",
        "        x, H = args\n",
        "\n",
        "        #temp = self.A@x\n",
        "        #temp  = temp* H\n",
        "        #temp = self.A_f_T@temp\n",
        "     \n",
        "        x = self.A_f_T@(self.A@x * H)\n",
        "       \n",
        "        #x = x*H\n",
        "        #return temp\n",
        "        return x\n",
        "   \n",
        "    # Takes X frames, splits them into chunks of 2x2 and then zero pads them at the end \n",
        "    # of each row/col/frame  by 2 ,so we have N numbers of chunks of 4x4\n",
        "    # Move time axis to correct position - > X(2 frames) | N(blocks) | Frame | Width | Hight \n",
        "    def img_to_blcks(self, frames):\n",
        "        a1 = tf.split(frames, frames.shape[2]//2, axis = 2)\n",
        "        a2 = tf.split(a1, frames.shape[1]//2, axis = 2)\n",
        "        a3 = tf.reshape(a2, shape = ((tf.shape(frames)[2]//2)*(tf.shape(frames)[1]//2),  2,2))\n",
        "        return a3\n",
        "    \n",
        "    \n",
        "    def call_batches(self, inputs):\n",
        "        # Called on batches of data , will call each filter as many times until over.\n",
        "        #repeated on dim 1 bacthes \n",
        "        filters1 = tf.split(self.useable_filters, self.useable_filters.shape[1], axis = 1)\n",
        "        filters1 = tf.repeat(filters1, (self.groups_of_2//self.initial_channels)*self.blocks, axis = 2)\n",
        "        filters1 = (tf.concat(   tf.split(filters1, filters1.shape[0], axis = 0), 2 ))\n",
        "        filters1 = tf.squeeze(filters1, axis= 0)\n",
        "        test_inputs = tf.repeat(tf.expand_dims(inputs , axis = 0), self.kern_num, axis = 0)\n",
        "        return self.kernels(test_inputs, filters1)\n",
        "    \n",
        "\n",
        "    def kernels(self, x, all_h):\n",
        "        # Seperates all the channels (output) KERNELS and performs convolution in parallel on all of them.\n",
        "        return tf.vectorized_map( self.conv_channel, (x, all_h))\n",
        "\n",
        "\n",
        "    def conv_channel(self, args):\n",
        "        # Performs convolution on a single channel.\n",
        "        x, h = args\n",
        "        \n",
        "        x = tf.reshape(x, shape = (tf.shape(x)[0], 64, 1))\n",
        "        h = tf.reshape(h, shape = (tf.shape(h)[0],  64, 1))\n",
        "        \n",
        "        # In case of 1 channel this is fine , BUT in case of many channels this need to be moved 1 step above\n",
        "        # either at kernels or even better on call_batches so we dont do the same matmul everytime.\n",
        "        # Same goes for the flattens ^^\n",
        "        h = self.C_T@h\n",
        "      \n",
        "        return tf.vectorized_map( self.trans_conv, (x, h) )\n",
        "    \n",
        "\n",
        "    @tf.function(experimental_compile=True)\n",
        "    def __call__(self, inputs):#main_call_on_batches\n",
        "        #print(tf.executing_eagerly())\n",
        "        # will split it into groups of 2 frames (NON overlapping)\n",
        "        # We put all our inputs in serial meaning we put each channel of each \"frame\" one after another\n",
        "        # Inputs must be of shape SIZE->DIM1->DIM2->CHANNELS\n",
        "        \n",
        "        inputs = tf.concat(    tf.split(inputs, inputs.shape[4], axis = 4), 1 )\n",
        "        inputs = tf.experimental.numpy.moveaxis(inputs, 0, 1)\n",
        "        \n",
        "        img_blks = tf.vectorized_map(self.img_to_blcks, inputs)\n",
        "        img_blks = tf.reshape(img_blks, (tf.shape(img_blks)[0]//2, 2, tf.shape(img_blks)[1],\n",
        "                                                tf.shape(img_blks)[2], tf.shape(img_blks)[3])  )\n",
        "        img_blks = tf.pad(img_blks, tf.constant([[0, 0], [0, 2], [0, 0], [0, 2], [0, 2]]), \"CONSTANT\")\n",
        "\n",
        "        padded_blocks = tf.experimental.numpy.moveaxis(img_blks, 1, 2)\n",
        "        padded_blocks = tf.expand_dims(padded_blocks, axis = 0)\n",
        "        padded_blocks = tf.reshape(padded_blocks, (self.bacthes, self.groups_of_2*self.blocks, 4, 4, 4))\n",
        "        # ABOVE NEED TO BE FIXED FOR MANY BATCHES CURRENTLY WORKS FOR ONLY 1 BATCH\n",
        "        # \n",
        "\n",
        "        co_blocks =  tf.vectorized_map( self.call_batches,  padded_blocks)\n",
        "        \n",
        "        #reshape from 64 to 4x4x4\n",
        "        co_blocks = tf.reshape(co_blocks, shape = (tf.shape(co_blocks)[0], tf.shape(co_blocks)[1], \n",
        "                                                  tf.shape(co_blocks)[2], 4, 4, 4))\n",
        "        \n",
        "        #PUSH ALL DIMENSIONS 1 to the right for batches and it was another one for the kernels\n",
        "        #PEFRORMS THE BLOCKS TO IMAGE \n",
        "        co_blocks = tf.reshape(co_blocks, (self.bacthes, self.kern_num, \n",
        "                                                         self.groups_of_2, self.blocks, 4, 4, 4))\n",
        "        \n",
        "        #groupsof 2| frames| blocks|  <><><>   h|w or w|h DOENST MATTER\n",
        "        co_blocks = tf.experimental.numpy.moveaxis(co_blocks, 4, 3)\n",
        "        \n",
        "        co_blocks = tf.reshape(co_blocks, \n",
        "                                      (self.bacthes, self.kern_num, \n",
        "                                       tf.shape(co_blocks)[2]*tf.shape(co_blocks)[3], \n",
        "                                       self.blocks, 4, 4))\n",
        "        \n",
        "        co_blocks = tf.reshape(co_blocks, \n",
        "                                  ( self.bacthes, self.kern_num, \n",
        "                                   tf.shape(co_blocks)[2], \n",
        "                                   self.w//2, self.h//2, 4, 4) )\n",
        "     \n",
        "        co_blocks = tf.transpose(co_blocks, [0, 1, 2, 3, 5, 4, 6])\n",
        "        co_blocks = tf.reshape(co_blocks, (self.bacthes, self.kern_num, \n",
        "                                                 tf.shape(co_blocks)[2], 1, self.w*2, \n",
        "                                                 self.h*2 ) ) \n",
        "        \n",
        "        co_blocks =  tf.reshape(co_blocks, (self.bacthes, self.kern_num, \n",
        "                                                  tf.shape(co_blocks)[2], tf.shape(co_blocks)[4] , \n",
        "                                                  tf.shape(co_blocks)[5]))\n",
        "        \n",
        "        # PERFORM OVERLAP ADD METHOD *** NOTE THAT THIS WILL OVERLAP ADD THE ACTUAL DIMENSIONS OF THE \"FRAMES\"\n",
        "        # EFFECTIVEVELY \"SQUEEZING\" THE \"FRAMES\" AND NOT THE NUMBER OF FRAMES THEMSELVES ***\n",
        "        oa = tf.reshape(co_blocks, \n",
        "                        (self.bacthes, self.kern_num, \n",
        "                         tf.shape(co_blocks)[2], tf.shape(co_blocks)[3] , tf.shape(co_blocks)[4]//4, 4))\n",
        "        \n",
        "        oa = tf.signal.overlap_and_add(oa, 2)\n",
        "        oa = tf.transpose(oa, [0, 1, 2, 4, 3])\n",
        "        oa = tf.reshape(oa, (self.bacthes, self.kern_num, tf.shape(oa)[2], tf.shape(oa)[3], tf.shape(oa)[4]//4, 4))\n",
        "        oa = tf.signal.overlap_and_add(oa, 2)\n",
        "        oa =  tf.transpose(oa, [0, 1, 2, 4, 3])\n",
        "        \n",
        "        # Split the final reults in X ,because we took the X channels of each frame and \"flattened\" them .\n",
        "        # Also add the results of each channel together to form the final feature maps .\n",
        "        maps = tf.math.reduce_sum(tf.split(oa, self.initial_channels, axis=2), axis = 0 )\n",
        "        maps = tf.experimental.numpy.moveaxis(maps, 1, 4)\n",
        "        \n",
        "        # We got X inputs and we produced 2*X feature maps, so we need to add them in the correct order \n",
        "        # to form the correct feature maps\n",
        "        # Order is : 1 + 3 | 2 + 4 | 5 + 7 | 6 + 8 and so on ...(but starting at 2)\n",
        "        # Also we skip the very first and last elements and we start counting from the 3rd element\n",
        "        # Also the 2 nd element is the 1st of our desired output in case of odd length input\n",
        "        # And in case of even input we need to append the second last element \n",
        "        a_OPT_INDEX = maps[:, 2::2]\n",
        "        b_OPT_INDEX  = maps[:, 3::2]\n",
        "\n",
        "        a_OPT_INDEX = a_OPT_INDEX[:, 0:-1]\n",
        "        b_OPT_INDEX = b_OPT_INDEX[:, 0:-1]\n",
        "\n",
        "        a_OPT_INDEX = tf.split(a_OPT_INDEX, a_OPT_INDEX.shape[1]//2 , axis = 1)\n",
        "        b_OPT_INDEX = tf.split(b_OPT_INDEX, b_OPT_INDEX.shape[1]//2 , axis = 1)\n",
        "\n",
        "        pre_mid_maps = tf.concat([tf.expand_dims(a_OPT_INDEX, axis = 1), tf.expand_dims(b_OPT_INDEX, axis = 1)], axis=1)\n",
        "        pre_mid_maps = (tf.math.reduce_sum(pre_mid_maps, axis = 3))\n",
        "\n",
        "        mid_maps =tf.reshape(pre_mid_maps, \n",
        "                             (tf.shape(pre_mid_maps)[0]*tf.shape(pre_mid_maps)[1],\n",
        "                              tf.shape(pre_mid_maps)[2],tf.shape(pre_mid_maps)[3],tf.shape(pre_mid_maps)[4],\n",
        "                             tf.shape(pre_mid_maps)[5]))\n",
        "\n",
        "        mid_maps = tf.experimental.numpy.moveaxis(mid_maps, 0, 1)\n",
        "        maps = tf.concat([tf.expand_dims( maps[:,1], axis =1), mid_maps, tf.expand_dims( maps[:, -2], axis =1)], axis = 1)\n",
        "        \n",
        "        return maps[ :, :,  1:-1, 1:-1, :]/64# C matrice is *64 so we must divide the result.\n"
      ],
      "metadata": {
        "id": "5FTfxY35Qezq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "precision = tf.float32\n",
        "\n",
        "curr_path = \"/content/drive/MyDrive/fast3/\"\n",
        "A = np.load(curr_path+'A.npy')\n",
        "C = np.load(curr_path+'C.npy')\n",
        "\n",
        "C = np.flipud(C)\n",
        "A_f = np.fliplr(A)\n",
        "A_f_T = A_f.T\n",
        "C_T = C.T\n",
        "\n",
        "A = tf.convert_to_tensor(A, dtype=precision)\n",
        "C = tf.convert_to_tensor(C, dtype=precision)\n",
        "A_f_T = tf.convert_to_tensor(A_f_T, dtype=precision)\n",
        "C_T = tf.convert_to_tensor(C_T, dtype=precision)  \n"
      ],
      "metadata": {
        "id": "32V4QHCwRDuh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "kernels = 1\n",
        "batches = 1#broken after last changes\n",
        "frames = 100#must be greater than 4\n",
        "dim1 = 128\n",
        "dim2 = 128\n",
        "channels = 1\n",
        "\n",
        "video = np.ones(shape = ( batches, frames, dim1, dim2, channels))\n",
        "video = tf.convert_to_tensor(video, dtype=precision)\n",
        "\n"
      ],
      "metadata": {
        "id": "b4qVpsFzQjCU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "layerMY = myConv( no_kernels = kernels ,input_shape =( batches, frames, dim1, dim2, channels) )\n",
        "\n",
        "filters = layerMY.getme()\n",
        "filters = tf.convert_to_tensor(filters, dtype=precision)\n",
        "filters = tf.reshape(filters, ( 3, 3, 3, channels, kernels))\n",
        "\n",
        "x = layerMY(video)\n",
        "x1 = tf.nn.conv3d(video, filters, strides = (1,1,1,1,1), padding = \"SAME\")\n",
        "\n",
        "\n",
        "value = PSNR(x1, x)\n",
        "value = np.array(value)   \n",
        "print(f\"PSNR value is {value} dB\")\n",
        "#psnr1 = tf.image.psnr(x, x1, max_val=tf.reduce_max(tf.math.maximum(x, x1)))\n",
        "#print(psnr1)"
      ],
      "metadata": {
        "id": "dobPiXMjVVCv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kernels = 1\n",
        "batches = 1#broken after last changes\n",
        "frames = 56#must be greater than 4\n",
        "dim1 = 18\n",
        "dim2 = 18\n",
        "channels = 1\n",
        "\n",
        "video = np.ones(shape = ( batches, frames, dim1, dim2, channels))\n",
        "video = tf.convert_to_tensor(video, dtype=precision)\n",
        "\n",
        "layerMY = myConv( no_kernels = kernels ,input_shape =( batches, frames, dim1, dim2, channels) )\n",
        "layerTE = tf.keras.layers.Conv3D(kernels, (3,3,3),strides = (1,1,1), \n",
        "                                 padding = \"same\", input_shape=( batches,frames, dim1, \n",
        "                                                                dim2, channels), use_bias=False)"
      ],
      "metadata": {
        "id": "sGr1-weBj4UP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K2FDAc_glzSW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def my():\n",
        "  x = layerMY(video)\n",
        "  return x\n",
        "my()\n",
        "my_time = timeit.timeit('my()', number=1000, setup=\"from __main__ import my\")\n",
        "\n",
        "print(my_time)"
      ],
      "metadata": {
        "id": "brOOXoLohwcN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def tens():\n",
        "  x = layerTE(video)\n",
        "  return x\n",
        "tens()\n",
        "tens_time = timeit.timeit('tens()', number=1000, setup=\"from __main__ import tens\")\n",
        "\n",
        "print(tens_time)"
      ],
      "metadata": {
        "id": "o5inGcbRjDHP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}